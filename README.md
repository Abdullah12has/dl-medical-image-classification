
Transfer Learning for Medical Image Classification
     Instructed  by Haotian Liu (haotian.liu@oulu.fi)

Motivation: In medical imaging, obtaining large, labeled datasets is often challenging due to privacy concerns, high annotation costs, and limited availability of expert knowledge. To effectively learn and boost performance on these smaller datasets, we leverage transfer learning techniques, which consist of models that are trained on huge amounts of data.
Goal: Improve the performance of diabetic retinopathy detection using transfer learning by fine-tuning models and understanding the classification results with visualizations and explainable AI.
Requirements:

     1. Complete the project and submit the code. For the code, you can get help from github. (45 points)

          The DeepDRiD dataset, template code, and online evaluation are available on Kaggle: https://www.kaggle.com/t/41e0944a6839469fadd529fabab45e06. You should only use this dataset for final project purposes.

          You are required to complete a few tasks as follows. Please check the instruction document below for more information.

          a) Fine-tune a pre-trained model using the DeepDRiD dataset. (5 points)

          b) Two-stage training with additional datasets. (5 points)

          c) Incorporate attention mechanisms in the model. (10 points)

          d) Compare the performance of different models and strategies. (20 points)

          e) Creating Visualizations and Explainable AI. (5 points)

     2. Submit a report for this project. (15 points)

          The report should include a description of the methods used in the project, experimental results, and discussions.


          Please include your team name(s) of Kaggle in the Google form above. The report should include the results of the DeepDRiD test set.


          The plagiarism check rate of the report needs to be less than 20% (excluding references). 



Hints:
For GPU computation resources, you can choose to use the CSC student project, Google Colab, and computer rooms in TS135.
We encourage students to get code inspiration from GitHub. Please submit the zip file, which includes your code, trained model, and a readme.md file (explaining how to run the code). We also accept the code in notebook or Python script form.
Students can create a Google link, upload the trained checkpoints there, and send the link when they submit the final project. You can choose to put the link in the report.
