{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import copy\n", "import os\n", "import random\n", "import sys"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np \n", "import pandas as pd\n", "import torch\n", "import torch.nn as nn\n", "from PIL import Image\n", "from sklearn.metrics import cohen_kappa_score, precision_score, recall_score, accuracy_score\n", "from torch.utils.data import Dataset, DataLoader\n", "from torchvision import models, transforms\n", "from torchvision.transforms.functional import to_pil_image\n", "from tqdm import tqdm"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Hyper Parameters"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["batch_size = 24\n", "num_classes = 5  # 5 DR levels\n", "learning_rate = 0.0001\n", "num_epochs = 20"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class RetinopathyDataset(Dataset):\n", "    def __init__(self, ann_file, image_dir, transform=None, mode='single', test=False):\n", "        self.ann_file = ann_file\n", "        self.image_dir = image_dir\n", "        self.transform = transform\n", "        self.test = test\n", "        self.mode = mode\n", "        if self.mode == 'single':\n", "            self.data = self.load_data()\n", "        else:\n", "            self.data = self.load_data_dual()\n", "    def __len__(self):\n", "        return len(self.data)\n", "    def __getitem__(self, index):\n", "        if self.mode == 'single':\n", "            return self.get_item(index)\n", "        else:\n", "            return self.get_item_dual(index)\n\n", "    # 1. single image\n", "    def load_data(self):\n", "        df = pd.read_csv(self.ann_file)\n", "        data = []\n", "        for _, row in df.iterrows():\n", "            file_info = dict()\n", "            file_info['img_path'] = os.path.join(self.image_dir, row['img_path'])\n", "            if not self.test:\n", "                file_info['dr_level'] = int(row['patient_DR_Level'])\n", "            data.append(file_info)\n", "        return data\n", "    def get_item(self, index):\n", "        data = self.data[index]\n", "        img = Image.open(data['img_path']).convert('RGB')\n", "        if self.transform:\n", "            img = self.transform(img)\n", "        if not self.test:\n", "            label = torch.tensor(data['dr_level'], dtype=torch.int64)\n", "            return img, label\n", "        else:\n", "            return img\n\n", "    # 2. dual image\n", "    def load_data_dual(self):\n", "        df = pd.read_csv(self.ann_file)\n", "        df['prefix'] = df['image_id'].str.split('_').str[0]  # The patient id of each image\n", "        df['suffix'] = df['image_id'].str.split('_').str[1].str[0]  # The left or right eye\n", "        grouped = df.groupby(['prefix', 'suffix'])\n", "        data = []\n", "        for (prefix, suffix), group in grouped:\n", "            file_info = dict()\n", "            file_info['img_path1'] = os.path.join(self.image_dir, group.iloc[0]['img_path'])\n", "            file_info['img_path2'] = os.path.join(self.image_dir, group.iloc[1]['img_path'])\n", "            if not self.test:\n", "                file_info['dr_level'] = int(group.iloc[0]['patient_DR_Level'])\n", "            data.append(file_info)\n", "        return data\n", "    def get_item_dual(self, index):\n", "        data = self.data[index]\n", "        img1 = Image.open(data['img_path1']).convert('RGB')\n", "        img2 = Image.open(data['img_path2']).convert('RGB')\n", "        if self.transform:\n", "            img1 = self.transform(img1)\n", "            img2 = self.transform(img2)\n", "        if not self.test:\n", "            label = torch.tensor(data['dr_level'], dtype=torch.int64)\n", "            return [img1, img2], label\n", "        else:\n", "            return [img1, img2]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class CutOut(object):\n", "    def __init__(self, mask_size, p=0.5):\n", "        self.mask_size = mask_size\n", "        self.p = p\n", "    def __call__(self, img):\n", "        if np.random.rand() > self.p:\n", "            return img\n\n", "        # Ensure the image is a tensor\n", "        if not isinstance(img, torch.Tensor):\n", "            raise TypeError('Input image must be a torch.Tensor')\n\n", "        # Get height and width of the image\n", "        h, w = img.shape[1], img.shape[2]\n", "        mask_size_half = self.mask_size // 2\n", "        offset = 1 if self.mask_size % 2 == 0 else 0\n", "        cx = np.random.randint(mask_size_half, w + offset - mask_size_half)\n", "        cy = np.random.randint(mask_size_half, h + offset - mask_size_half)\n", "        xmin, xmax = cx - mask_size_half, cx + mask_size_half + offset\n", "        ymin, ymax = cy - mask_size_half, cy + mask_size_half + offset\n", "        xmin, xmax = max(0, xmin), min(w, xmax)\n", "        ymin, ymax = max(0, ymin), min(h, ymax)\n", "        img[:, ymin:ymax, xmin:xmax] = 0\n", "        return img"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class SLORandomPad:\n", "    def __init__(self, size):\n", "        self.size = size\n", "    def __call__(self, img):\n", "        pad_width = max(0, self.size[0] - img.width)\n", "        pad_height = max(0, self.size[1] - img.height)\n", "        pad_left = random.randint(0, pad_width)\n", "        pad_top = random.randint(0, pad_height)\n", "        pad_right = pad_width - pad_left\n", "        pad_bottom = pad_height - pad_top\n", "        return transforms.functional.pad(img, (pad_left, pad_top, pad_right, pad_bottom))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class FundRandomRotate:\n", "    def __init__(self, prob, degree):\n", "        self.prob = prob\n", "        self.degree = degree\n", "    def __call__(self, img):\n", "        if random.random() < self.prob:\n", "            angle = random.uniform(-self.degree, self.degree)\n", "            return transforms.functional.rotate(img, angle)\n", "        return img"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["transform_train = transforms.Compose([\n", "    transforms.Resize((256, 256)),\n", "    transforms.RandomCrop((210, 210)),\n", "    SLORandomPad((224, 224)),\n", "    FundRandomRotate(prob=0.5, degree=30),\n", "    transforms.RandomHorizontalFlip(p=0.5),\n", "    transforms.RandomVerticalFlip(p=0.5),\n", "    transforms.ColorJitter(brightness=(0.1, 0.9)),\n", "    transforms.ToTensor(),\n", "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n", "])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["transform_test = transforms.Compose([\n", "    transforms.Resize((224, 224)),\n", "    transforms.ToTensor(),\n", "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n", "])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def train_model(model, train_loader, val_loader, device, criterion, optimizer, lr_scheduler, num_epochs=25,\n", "                checkpoint_path='model.pth'):\n", "    best_model = model.state_dict()\n", "    best_epoch = None\n", "    best_val_kappa = -1.0  # Initialize the best kappa score\n", "    for epoch in range(1, num_epochs + 1):\n", "        print(f'\\nEpoch {epoch}/{num_epochs}')\n", "        running_loss = []\n", "        all_preds = []\n", "        all_labels = []\n", "        model.train()\n", "        with tqdm(total=len(train_loader), desc=f'Training', unit=' batch', file=sys.stdout) as pbar:\n", "            for images, labels in train_loader:\n", "                if not isinstance(images, list):\n", "                    images = images.to(device)  # single image case\n", "                else:\n", "                    images = [x.to(device) for x in images]  # dual images case\n", "                labels = labels.to(device)\n", "                optimizer.zero_grad()\n", "                outputs = model(images)\n", "                loss = criterion(outputs, labels.long())\n", "                loss.backward()\n", "                optimizer.step()\n", "                preds = torch.argmax(outputs, 1)\n", "                all_preds.extend(preds.cpu().numpy())\n", "                all_labels.extend(labels.cpu().numpy())\n", "                running_loss.append(loss.item())\n", "                pbar.set_postfix({'lr': f'{optimizer.param_groups[0][\"lr\"]:.1e}', 'Loss': f'{loss.item():.4f}'})\n", "                pbar.update(1)\n", "        lr_scheduler.step()\n", "        epoch_loss = sum(running_loss) / len(running_loss)\n", "        train_metrics = compute_metrics(all_preds, all_labels, per_class=True)\n", "        kappa, accuracy, precision, recall = train_metrics[:4]\n", "        print(f'[Train] Kappa: {kappa:.4f} Accuracy: {accuracy:.4f} '\n", "              f'Precision: {precision:.4f} Recall: {recall:.4f} Loss: {epoch_loss:.4f}')\n", "        if len(train_metrics) > 4:\n", "            precision_per_class, recall_per_class = train_metrics[4:]\n", "            for i, (precision, recall) in enumerate(zip(precision_per_class, recall_per_class)):\n", "                print(f'[Train] Class {i}: Precision: {precision:.4f}, Recall: {recall:.4f}')\n\n", "        # Evaluation on the validation set at the end of each epoch\n", "        val_metrics = evaluate_model(model, val_loader, device)\n", "        val_kappa, val_accuracy, val_precision, val_recall = val_metrics[:4]\n", "        print(f'[Val] Kappa: {val_kappa:.4f} Accuracy: {val_accuracy:.4f} '\n", "              f'Precision: {val_precision:.4f} Recall: {val_recall:.4f}')\n", "        if val_kappa > best_val_kappa:\n", "            best_val_kappa = val_kappa\n", "            best_epoch = epoch\n", "            best_model = model.state_dict()\n", "            torch.save(best_model, checkpoint_path)\n", "    print(f'[Val] Best kappa: {best_val_kappa:.4f}, Epoch {best_epoch}')\n", "    return model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def evaluate_model(model, test_loader, device, test_only=False, prediction_path='./test_predictions.csv'):\n", "    model.eval()\n", "    all_preds = []\n", "    all_labels = []\n", "    all_image_ids = []\n", "    with tqdm(total=len(test_loader), desc=f'Evaluating', unit=' batch', file=sys.stdout) as pbar:\n", "        for i, data in enumerate(test_loader):\n", "            if test_only:\n", "                images = data\n", "            else:\n", "                images, labels = data\n", "            if not isinstance(images, list):\n", "                images = images.to(device)  # single image case\n", "            else:\n", "                images = [x.to(device) for x in images]  # dual images case\n", "            with torch.no_grad():\n", "                outputs = model(images)\n", "                preds = torch.argmax(outputs, 1)\n", "            if not isinstance(images, list):\n", "                # single image case\n", "                all_preds.extend(preds.cpu().numpy())\n", "                image_ids = [\n", "                    os.path.basename(test_loader.dataset.data[idx]['img_path']) for idx in\n", "                    range(i * test_loader.batch_size, i * test_loader.batch_size + len(images))\n", "                ]\n", "                all_image_ids.extend(image_ids)\n", "                if not test_only:\n", "                    all_labels.extend(labels.numpy())\n", "            else:\n", "                # dual images case\n", "                for k in range(2):\n", "                    all_preds.extend(preds.cpu().numpy())\n", "                    image_ids = [\n", "                        os.path.basename(test_loader.dataset.data[idx][f'img_path{k + 1}']) for idx in\n", "                        range(i * test_loader.batch_size, i * test_loader.batch_size + len(images[k]))\n", "                    ]\n", "                    all_image_ids.extend(image_ids)\n", "                    if not test_only:\n", "                        all_labels.extend(labels.numpy())\n", "            pbar.update(1)\n\n", "    # Save predictions to csv file for Kaggle online evaluation\n", "    if test_only:\n", "        df = pd.DataFrame({\n", "            'ID': all_image_ids,\n", "            'TARGET': all_preds\n", "        })\n", "        df.to_csv(prediction_path, index=False)\n", "        print(f'[Test] Save predictions to {os.path.abspath(prediction_path)}')\n", "    else:\n", "        metrics = compute_metrics(all_preds, all_labels)\n", "        return metrics"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def compute_metrics(preds, labels, per_class=False):\n", "    kappa = cohen_kappa_score(labels, preds, weights='quadratic')\n", "    accuracy = accuracy_score(labels, preds)\n", "    precision = precision_score(labels, preds, average='weighted', zero_division=0)\n", "    recall = recall_score(labels, preds, average='weighted', zero_division=0)\n\n", "    # Calculate and print precision and recall for each class\n", "    if per_class:\n", "        precision_per_class = precision_score(labels, preds, average=None, zero_division=0)\n", "        recall_per_class = recall_score(labels, preds, average=None, zero_division=0)\n", "        return kappa, accuracy, precision, recall, precision_per_class, recall_per_class\n", "    return kappa, accuracy, precision, recall"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class MyModel(nn.Module):\n", "    def __init__(self, num_classes=5, dropout_rate=0.5):\n", "        super().__init__()\n", "        self.backbone = models.vgg16(pretrained=True)\n", "        self.backbone.fc = nn.Identity()  # Remove the original classification layer\n", "        self.fc = nn.Sequential(\n", "            nn.Linear(512 * 7 * 7, 256),\n", "            nn.ReLU(inplace=True),\n", "            nn.Dropout(p=dropout_rate),\n", "            nn.Linear(256, 128),\n", "            nn.ReLU(inplace=True),\n", "            nn.Dropout(p=dropout_rate),\n", "            nn.Linear(128, num_classes)\n", "        )\n", "    def forward(self, x):\n", "        x = self.backbone.features(x)\n", "        x = torch.flatten(x, 1) \n", "        x = self.fc(x)\n", "        return x"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class MyDualModel(nn.Module):\n", "    def __init__(self, num_classes=5, dropout_rate=0.5):\n", "        super().__init__()\n", "        backbone = models.VGG(init_weights=True)\n", "        backbone.fc = nn.Identity()\n\n", "        # Here the two backbones will have the same structure but unshared weights\n", "        self.backbone1 = copy.deepcopy(backbone)\n", "        self.backbone2 = copy.deepcopy(backbone)\n", "        self.fc = nn.Sequential(\n", "            nn.Linear(512 * 2, 256),\n", "            nn.ReLU(inplace=True),\n", "            nn.Dropout(p=dropout_rate),\n", "            nn.Linear(256, 128),\n", "            nn.ReLU(inplace=True),\n", "            nn.Dropout(p=dropout_rate),\n", "            nn.Linear(128, num_classes)\n", "        )\n", "    def forward(self, images):\n", "        image1, image2 = images\n", "        x1 = self.backbone1(image1)\n", "        x2 = self.backbone2(image2)\n", "        x = torch.cat((x1, x2), dim=1)\n", "        x = self.fc(x)\n", "        return x"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if __name__ == '__main__':\n", "    # Choose between 'single image' and 'dual images' pipeline\n", "    # This will affect the model definition, dataset pipeline, training and evaluation\n\n", "    #TODO: change mode here\n", "    mode = 'single'  # forward single image to the model each time \n", "    # mode = 'dual'  # forward two images of the same eye to the model and fuse the features\n", "    assert mode in ('single', 'dual')\n\n", "    # Define the model\n", "    if mode == 'single':\n", "        model = MyModel()\n", "    else:\n", "        model = MyDualModel()\n", "    print(model, '\\n')\n", "    print('Pipeline Mode:', mode)\n\n", "    # Create datasets\n", "    train_dataset = RetinopathyDataset('./DeepDRiD/train.csv', './DeepDRiD/train/', transform_train, mode)\n", "    val_dataset = RetinopathyDataset('./DeepDRiD/val.csv', './DeepDRiD/val/', transform_test, mode)\n", "    test_dataset = RetinopathyDataset('./DeepDRiD/test.csv', './DeepDRiD/test/', transform_test, mode, test=True)\n\n", "    # Create dataloaders\n", "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n", "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n", "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\n", "    # Define the weighted CrossEntropyLoss\n", "    criterion = nn.CrossEntropyLoss()\n\n", "    # Use GPU device is possible\n", "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n", "    print('Device:', device)\n\n", "    # Move class weights to the device\n", "    model = model.to(device)\n\n", "    # Optimizer and Learning rate scheduler\n", "    optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate)\n", "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n\n", "    # Train and evaluate the model with the training and validation set\n", "    model = train_model(\n", "        model, train_loader, val_loader, device, criterion, optimizer,\n", "        lr_scheduler=lr_scheduler, num_epochs=num_epochs,\n", "        checkpoint_path='./model_1.pth'\n", "    )\n\n", "    # Load the pretrained checkpoint\n", "    state_dict = torch.load('./model_1.pth', map_location='cpu')\n", "    model.load_state_dict(state_dict, strict=True)\n\n", "    # Make predictions on testing set and save the prediction results\n", "    evaluate_model(model, test_loader, device, test_only=True)"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}